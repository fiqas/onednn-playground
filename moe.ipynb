{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7004a127-a4dc-4522-95d8-0ec465915725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from itertools import count\n",
    "import sys\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Export stuffs!\n",
    "exported = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79a0e9f-1103-4d91-b14e-b8d54a717790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expert_num = 64 # number of experts\n",
    "expert_dim = 512\n",
    "emb_dim = 256 # embedding size\n",
    "token_num = 2048 # think token count, from unrolled batches possibly\n",
    "\n",
    "# token count * embedding size\n",
    "words = randn(token_num, emb_dim).astype(np.float32)\n",
    "exported[\"src\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ae5abfb-78af-4097-a3cd-891ee42a7133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# expert (3) * emb_size (5) * emb_size (5)\n",
    "experts_w1 = randn(expert_num, emb_dim, expert_dim).astype(np.float32)\n",
    "exported[\"experts_w1\"] = experts_w1\n",
    "\n",
    "# expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "experts_b1 = randn(expert_num, 1, expert_dim).astype(np.float32)\n",
    "exported[\"experts_b1\"] = experts_b1\n",
    "\n",
    "# expert (3) * emb_size (5) * emb_size (5)\n",
    "experts_w2 = randn(expert_num, expert_dim, emb_dim).astype(np.float32)\n",
    "exported[\"experts_w2\"] = experts_w2\n",
    "\n",
    "# expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "experts_b2 = randn(expert_num, 1, emb_dim).astype(np.float32)\n",
    "exported[\"experts_b2\"] = experts_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0525a698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 64)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Generate random binary router\n",
    "\n",
    "router = np.zeros((token_num, expert_num)).astype(np.float32)\n",
    "print(router.shape)\n",
    "\n",
    "# Fill it with ones with each expert getting token_num / expert_num amount of tokens in it. Then shuffle.\n",
    "tokens_per_expert = token_num / expert_num\n",
    "\n",
    "counter = 0\n",
    "shift = 0\n",
    "expert = 0\n",
    "for t in range(token_num):\n",
    "    router[t][expert + shift] = 1\n",
    "    counter += 1\n",
    "    if counter == tokens_per_expert:\n",
    "        counter = 0\n",
    "        shift += 1\n",
    "\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "#print(router)\n",
    "\n",
    "np.random.shuffle(router)\n",
    "print(router)\n",
    "\n",
    "exported[\"router\"] = router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1a3256-64a7-4dbe-b1d4-ea86d875ea27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70429174-2e92-44b1-8bf0-e4aed9a6a890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert 0:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 1:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 2:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 3:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 4:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 5:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 6:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 7:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 8:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 9:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 10:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 11:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 12:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 13:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 14:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 15:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 16:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 17:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 18:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 19:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 20:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 21:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 22:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 23:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 24:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 25:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 26:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 27:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 28:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 29:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 30:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 31:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 32:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 33:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 34:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 35:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 36:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 37:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 38:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 39:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 40:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 41:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 42:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 43:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 44:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 45:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 46:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 47:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 48:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 49:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 50:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 51:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 52:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 53:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 54:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 55:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 56:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 57:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 58:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 59:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 60:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 61:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 62:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Expert 63:\n",
      "  (1, 256) * (256, 512) + (1, 512) = (1, 512)\n",
      "\n",
      "  (1, 512) * (512, 256) + (1, 256) = (1, 256)\n",
      "\n",
      "Total output: (2048, 256)\n"
     ]
    }
   ],
   "source": [
    "b = 0.1\n",
    "\n",
    "# words(7) * emb_size(4)\n",
    "total_output = b * words # … so that if a word doesn't go through any expert it will still have some value\n",
    "\n",
    "# Repeat for every expert, looking at routed do determine which words go to said expert\n",
    "for n, expert_w1, expert_b1, expert_w2, expert_b2, mask in zip(count(), experts_w1, experts_b1, experts_w2, experts_b2, router):\n",
    "    print(f\"Expert {n}:\")\n",
    "    \n",
    "    # select all words where the mask for this expert is > 0\n",
    "    expert_input = words[mask.nonzero()]\n",
    "    \n",
    "    # classic matmul op for feed-forward I guess? + relu\n",
    "    expert_output1 = np.maximum(0.0, np.add(np.matmul(expert_input, expert_w1), expert_b1))\n",
    "    expert_output2 = np.maximum(0.0, np.add(np.matmul(expert_output1, expert_w2), expert_b2))\n",
    "\n",
    "    # I did assignment here, but could also be addition\n",
    "    total_output[mask.nonzero()] = expert_output2\n",
    "\n",
    "    print(f\"  {expert_input.shape} * {expert_w1.shape} + {expert_b1.shape} = {expert_output1.shape}\\n\")\n",
    "    print(f\"  {expert_output1.shape} * {expert_w2.shape} + {expert_b2.shape} = {expert_output2.shape}\\n\")\n",
    "    \n",
    "    exported[f\"expert_{n}_src\"] = expert_input\n",
    "    exported[f\"expert_{n}_dst\"] = expert_output2\n",
    "    \n",
    "print(f\"Total output: {total_output.shape}\")\n",
    "exported[\"dst\"] = total_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261b8f50-16b9-456d-be41-43a568d3b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"data.npz\", **exported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0aba73c-9359-4c69-878e-dcce81d278c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experts_w2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec766a4-922e-4e1d-95af-01209aceceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_128\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_256\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_512\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_128\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_256\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_512\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_256_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_128\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_256\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_512\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_128\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_256\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_512\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_512_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_128\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_256\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_512\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_128\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_256\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_512\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_1024_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_128\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_256\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_512\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_128\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_256\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_512\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_2048_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_128\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_256\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_512\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_128\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_256\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_512\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_8_exp-dim_4096_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_128\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_256\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_512\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_128\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_256\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_512\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_256_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_128\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_256\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_512\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_128\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_256\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_512\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_512_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_128\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_256\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_512\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_128\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_256\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_512\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_1024_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_128\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_256\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_512\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_128\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_256\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_512\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_2048_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_128\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_256\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_512\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_128\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_256\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_512\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_16_exp-dim_4096_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_128\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_256\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_512\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_128\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_256\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_512\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_2048\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_4096\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_512_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_128\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_256\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_512\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_2048\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_4096\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_1024_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_128\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_256\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_512\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_2048\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_4096\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_2048_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_128\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_256\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_512\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_2048\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_4096\n",
      "Finished  exp-num_32_exp-dim_256_emb-dim_4096_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_128\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_256\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_512\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_2048\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_4096\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_256_token-num_8192\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_512_token-num_128\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_512_token-num_256\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_512_token-num_512\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_512_token-num_1024\n",
      "Finished  exp-num_32_exp-dim_512_emb-dim_512_token-num_2048\n"
     ]
    }
   ],
   "source": [
    "# Do grid search generation for various variable values. Save them to separate files.\n",
    "# Do not run automatically LOL\n",
    "\n",
    "expert_num_list = [8, 16, 32, 64, 128, 256] # number of experts\n",
    "expert_dim_list = [256, 512, 1024, 2048, 4096]\n",
    "emb_dim_list = [256, 512, 1024, 2048, 4096] # embedding size\n",
    "token_num_list = [128, 256, 512, 1024, 2048, 4096, 8192] # think token count, from unrolled batches possibly\n",
    "\n",
    "\n",
    "for expert_num in expert_num_list:\n",
    "    for expert_dim in expert_dim_list:\n",
    "        for emb_dim in emb_dim_list:\n",
    "            for token_num in token_num_list:\n",
    "                \n",
    "                exported = dict()\n",
    "                \n",
    "                # Generate input\n",
    "                words = randn(token_num, emb_dim).astype(np.float32)\n",
    "                exported[\"src\"] = words\n",
    "                \n",
    "                # Generate parameters\n",
    "                experts_w1 = randn(expert_num, emb_dim, expert_dim).astype(np.float32)\n",
    "                exported[\"experts_w1\"] = experts_w1\n",
    "\n",
    "                # expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "                experts_b1 = randn(expert_num, 1, expert_dim).astype(np.float32)\n",
    "                exported[\"experts_b1\"] = experts_b1\n",
    "\n",
    "                # expert (3) * emb_size (5) * emb_size (5)\n",
    "                experts_w2 = randn(expert_num, expert_dim, emb_dim).astype(np.float32)\n",
    "                exported[\"experts_w2\"] = experts_w2\n",
    "\n",
    "                # expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "                experts_b2 = randn(expert_num, 1, emb_dim).astype(np.float32)\n",
    "                exported[\"experts_b2\"] = experts_b2\n",
    "\n",
    "                b = 0.1\n",
    "\n",
    "                # words(7) * emb_size(4)\n",
    "                total_output = b * words # … so that if a word doesn't go through any expert it will still have some value\n",
    "\n",
    "                # Repeat for every expert, looking at routed do determine which words go to said expert\n",
    "                for n, expert_w1, expert_b1, expert_w2, expert_b2, mask in zip(count(), experts_w1, experts_b1, experts_w2, experts_b2, router):\n",
    "                    #print(f\"Expert {n}:\")\n",
    "\n",
    "                    # select all words where the mask for this expert is > 0\n",
    "                    expert_input = words[mask.nonzero()]\n",
    "\n",
    "                    # classic matmul op for feed-forward I guess? + relu\n",
    "                    expert_output1 = np.maximum(0.0, np.add(np.matmul(expert_input, expert_w1), expert_b1))\n",
    "                    expert_output2 = np.maximum(0.0, np.add(np.matmul(expert_output1, expert_w2), expert_b2))\n",
    "\n",
    "                    # I did assignment here, but could also be addition\n",
    "                    total_output[mask.nonzero()] = expert_output2\n",
    "\n",
    "                    #print(f\"  {expert_input.shape} * {expert_w1.shape} + {expert_b1.shape} = {expert_output1.shape}\\n\")\n",
    "                    #print(f\"  {expert_output1.shape} * {expert_w2.shape} + {expert_b2.shape} = {expert_output2.shape}\\n\")\n",
    "\n",
    "                    exported[f\"expert_{n}_src\"] = expert_input\n",
    "                    exported[f\"expert_{n}_dst\"] = expert_output2\n",
    "\n",
    "                #print(f\"Total output: {total_output.shape}\")\n",
    "                exported[\"dst\"] = total_output\n",
    "                \n",
    "                file_name = \"exp-num_\" + str(expert_num) + \"_exp-dim_\" + str(expert_dim) + \"_emb-dim_\" + str(emb_dim) + \"_token-num_\" + str(token_num)\n",
    "                np.savez_compressed(file_name + \".npz\", **exported)\n",
    "                print(\"Finished \", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e150e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
