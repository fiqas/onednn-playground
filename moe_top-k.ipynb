{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7004a127-a4dc-4522-95d8-0ec465915725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from itertools import count\n",
    "import sys\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79a0e9f-1103-4d91-b14e-b8d54a717790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#expert_num = 64 # number of experts\n",
    "#expert_dim = 512\n",
    "#emb_dim = 256 # embedding size\n",
    "#token_num = 2048 # think token count, from unrolled batches possibly\n",
    "\n",
    "expert_num = 5 # number of experts\n",
    "expert_dim = 7\n",
    "emb_dim = 11 # embedding size\n",
    "token_num = 13 # think token count, from unrolled batches possibly\n",
    "\n",
    "# Bypass weight\n",
    "b = 0.1\n",
    "\n",
    "# Export sizes and bypass weight to C++ code as well\n",
    "exported = dict(\n",
    "    expert_count=expert_num,\n",
    "    expert_size=expert_dim,\n",
    "    embedding_size=emb_dim,\n",
    "    token_count=token_num,\n",
    "    b=np.array([b], dtype=np.float32) # I don't care that those numbers are longs, but I want this multiplier to be float32.\n",
    ")\n",
    "\n",
    "# token count * embedding size. Explicitly specifying order=C so it matches the C++ implementation.\n",
    "words = randn(token_num, emb_dim).astype(np.float32, order='C')\n",
    "exported[\"src\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7102606e-7dbb-483f-b53a-cc993dd8d589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6243454 , -0.6117564 , -0.5281718 , -1.0729686 ,  0.86540765,\n",
       "        -2.3015387 ,  1.7448118 , -0.7612069 ,  0.3190391 , -0.24937038,\n",
       "         1.4621079 ],\n",
       "       [-2.0601406 , -0.3224172 , -0.38405436,  1.1337694 , -1.0998913 ,\n",
       "        -0.1724282 , -0.8778584 ,  0.04221375,  0.58281523, -1.1006192 ,\n",
       "         1.1447237 ],\n",
       "       [ 0.9015907 ,  0.50249434,  0.90085596, -0.68372786, -0.12289023,\n",
       "        -0.93576944, -0.26788807,  0.53035545, -0.69166076, -0.39675352,\n",
       "        -0.6871727 ],\n",
       "       [-0.84520566, -0.6712461 , -0.0126646 , -1.1173104 ,  0.2344157 ,\n",
       "         1.6598022 ,  0.74204415, -0.19183555, -0.887629  , -0.7471583 ,\n",
       "         1.6924546 ],\n",
       "       [ 0.05080776, -0.6369957 ,  0.19091548,  2.1002553 ,  0.12015896,\n",
       "         0.6172031 ,  0.30017033, -0.35224986, -1.1425182 , -0.34934273,\n",
       "        -0.20889424],\n",
       "       [ 0.5866232 ,  0.8389834 ,  0.9311021 ,  0.2855873 ,  0.8851412 ,\n",
       "        -0.7543979 ,  1.2528682 ,  0.5129298 , -0.29809284,  0.48851815,\n",
       "        -0.07557172],\n",
       "       [ 1.1316293 ,  1.5198169 ,  2.1855755 , -1.3964963 , -1.4441139 ,\n",
       "        -0.5044659 ,  0.16003707,  0.8761689 ,  0.31563494, -2.0222013 ,\n",
       "        -0.30620402],\n",
       "       [ 0.8279746 ,  0.23009473,  0.7620112 , -0.22232814, -0.20075807,\n",
       "         0.18656139,  0.41005164,  0.19829972,  0.11900865, -0.6706623 ,\n",
       "         0.37756377],\n",
       "       [ 0.12182127,  1.1294839 ,  1.1989179 ,  0.18515642, -0.37528494,\n",
       "        -0.6387304 ,  0.42349437,  0.07734007, -0.34385368,  0.04359686,\n",
       "        -0.62000084],\n",
       "       [ 0.698032  , -0.44712856,  1.2245077 ,  0.40349165,  0.5935785 ,\n",
       "        -1.0949118 ,  0.16938244,  0.7405565 , -0.9537006 , -0.2662185 ,\n",
       "         0.03261455],\n",
       "       [-1.3731173 ,  0.31515938,  0.84616065, -0.85951596,  0.35054597,\n",
       "        -1.3122834 , -0.03869551, -1.6157724 ,  1.1214178 ,  0.40890053,\n",
       "        -0.02461696],\n",
       "       [-0.7751616 ,  1.2737559 ,  1.9671017 , -1.8579819 ,  1.236164  ,\n",
       "         1.6276507 ,  0.33801168, -1.199268  ,  0.8633453 , -0.1809203 ,\n",
       "        -0.60392064],\n",
       "       [-1.2300582 ,  0.55053747,  0.79280686, -0.62353075,  0.52057636,\n",
       "        -1.1443413 ,  0.80186105,  0.0465673 , -0.18656977, -0.10174587,\n",
       "         0.8688862 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae5abfb-78af-4097-a3cd-891ee42a7133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experts_w1 = randn(expert_num, emb_dim, expert_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_w1\"] = experts_w1\n",
    "\n",
    "experts_b1 = randn(expert_num, 1, expert_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_b1\"] = experts_b1\n",
    "\n",
    "experts_w2 = randn(expert_num, expert_dim, emb_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_w2\"] = experts_w2\n",
    "\n",
    "experts_b2 = randn(expert_num, 1, emb_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_b2\"] = experts_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd47b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scramble(a, axis=-1):\n",
    "    \"\"\"\n",
    "    Shuffle `a` in-place along the given axis.\n",
    "\n",
    "    Apply numpy.random.shuffle to the given axis of `a`.\n",
    "    Each one-dimensional slice is shuffled independently.\n",
    "    \"\"\"\n",
    "    b = a.swapaxes(axis, -1)\n",
    "    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n",
    "    # so `a` is shuffled in place, too.\n",
    "    shp = b.shape[:-1]\n",
    "    for ndx in np.ndindex(shp):\n",
    "        np.random.shuffle(b[ndx])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0525a698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 5)\n",
      "Total is 52.0, expected 52\n",
      "Expect around 10.4 per expert\n",
      "[10. 10.  9. 12. 11.]\n",
      "(5, 13)\n"
     ]
    }
   ],
   "source": [
    "# Generate random binary router\n",
    "\n",
    "router = np.zeros((token_num, expert_num)).astype(np.float32)\n",
    "print(router.shape)\n",
    "# Select K for TOP-K\n",
    "k = 4\n",
    "\n",
    "counter = 0\n",
    "expert = 0\n",
    "for t in range(token_num):\n",
    "    for counter in range(k):\n",
    "        router[t][expert + counter] = 1\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#print(router)\n",
    "\n",
    "# router_shuf = np.transpose(router)\n",
    "scramble(router, axis=-1)\n",
    "# router = np.transpose(router_shuf)\n",
    "\n",
    "# Sanity check: sum per expert\n",
    "print(f'Total is {np.sum(router)}, expected {token_num * k}')\n",
    "print(f'Expect around {token_num * k / expert_num} per expert')\n",
    "print(np.sum(router, axis=0))\n",
    "\n",
    "# Order seems to be [token,expert]. Flip it back to [expert,token] to make the for-loop easier\n",
    "router = np.transpose(router)\n",
    "print(router.shape)\n",
    "\n",
    "# Router can be tiny, we just need booleans -> uint8. Also order='C' necessary otherwise it\n",
    "# will be saved flipped, since we transposed router and numpy implements this by just\n",
    "# changing the memory order marker.\n",
    "exported[\"router\"] = router.astype(np.uint8, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c6c741-407a-4d3b-a7e8-3d9555bebe99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70429174-2e92-44b1-8bf0-e4aed9a6a890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert 0:\n",
      "Expert 0 gets 10.0 tokens\n",
      "  (10, 11) * (11, 7) + (1, 7) = (10, 7)\n",
      "\n",
      "  (10, 7) * (7, 11) + (1, 11) = (10, 11)\n",
      "\n",
      "input = [[ 1.6243454  -0.6117564  -0.5281718  -1.0729686   0.86540765 -2.3015387\n",
      "   1.7448118  -0.7612069   0.3190391  -0.24937038  1.4621079 ]\n",
      " [-2.0601406  -0.3224172  -0.38405436  1.1337694  -1.0998913  -0.1724282\n",
      "  -0.8778584   0.04221375  0.58281523 -1.1006192   1.1447237 ]\n",
      " [ 0.9015907   0.50249434  0.90085596 -0.68372786 -0.12289023 -0.93576944\n",
      "  -0.26788807  0.53035545 -0.69166076 -0.39675352 -0.6871727 ]\n",
      " [ 0.05080776 -0.6369957   0.19091548  2.1002553   0.12015896  0.6172031\n",
      "   0.30017033 -0.35224986 -1.1425182  -0.34934273 -0.20889424]\n",
      " [ 0.5866232   0.8389834   0.9311021   0.2855873   0.8851412  -0.7543979\n",
      "   1.2528682   0.5129298  -0.29809284  0.48851815 -0.07557172]\n",
      " [ 1.1316293   1.5198169   2.1855755  -1.3964963  -1.4441139  -0.5044659\n",
      "   0.16003707  0.8761689   0.31563494 -2.0222013  -0.30620402]\n",
      " [ 0.12182127  1.1294839   1.1989179   0.18515642 -0.37528494 -0.6387304\n",
      "   0.42349437  0.07734007 -0.34385368  0.04359686 -0.62000084]\n",
      " [-1.3731173   0.31515938  0.84616065 -0.85951596  0.35054597 -1.3122834\n",
      "  -0.03869551 -1.6157724   1.1214178   0.40890053 -0.02461696]\n",
      " [-0.7751616   1.2737559   1.9671017  -1.8579819   1.236164    1.6276507\n",
      "   0.33801168 -1.199268    0.8633453  -0.1809203  -0.60392064]\n",
      " [-1.2300582   0.55053747  0.79280686 -0.62353075  0.52057636 -1.1443413\n",
      "   0.80186105  0.0465673  -0.18656977 -0.10174587  0.8688862 ]]\n",
      "\n",
      "w1 = [[ 0.7504116   0.5294653   0.13770121  0.07782113  0.61838025  0.23249456\n",
      "   0.6825514 ]\n",
      " [-0.31011677 -2.4348378   1.0388246   2.1869795   0.44136444 -0.10015523\n",
      "  -0.13644475]\n",
      " [-0.11905419  0.01740941 -1.1220187  -0.51709443 -0.9970268   0.24879916\n",
      "  -0.29664114]\n",
      " [ 0.49521133 -0.17470317  0.98633516  0.21353391  2.1906998  -1.8963609\n",
      "  -0.6469167 ]\n",
      " [ 0.9014869   2.5283258  -0.24863477  0.04366899 -0.22631425  1.3314571\n",
      "  -0.28730786]\n",
      " [ 0.68006986 -0.3198016  -1.2725588   0.31354773  0.5031848   1.2932259\n",
      "  -0.11044703]\n",
      " [-0.6173621   0.56276107  0.2407371   0.28066507 -0.0731127   1.1603385\n",
      "   0.3694927 ]\n",
      " [ 1.9046587   1.1110567   0.6590498  -1.6274383   0.6023193   0.4202822\n",
      "   0.81095165]\n",
      " [ 1.044442   -0.4008782   0.8240056  -0.56230545  1.9548781  -1.3319516\n",
      "  -1.7606885 ]\n",
      " [-1.6507213  -0.89055556 -1.1191154   1.9560789  -0.3264995  -1.3426758\n",
      "   1.114383  ]\n",
      " [-0.58652395 -1.2368534   0.87583894  0.6233622  -0.43495667  1.40754\n",
      "   0.12910157]]\n",
      "\n",
      "b1 = [[ 0.6365834   1.4092534   1.6209123  -0.8061848  -0.2516742   0.38271517\n",
      "  -0.28899735]]\n",
      "\n",
      "output1 = [[0.         5.2830772  5.197967   0.         0.         4.573313\n",
      "  1.1360624 ]\n",
      " [1.0654786  0.         5.575427   0.         2.4512787  0.\n",
      "  0.        ]\n",
      " [1.4754058  2.7058415  1.3605483  0.         0.         1.0877504\n",
      "  1.5896249 ]\n",
      " [1.0673223  3.5350022  1.1148915  0.         1.929975   0.\n",
      "  0.        ]\n",
      " [0.26214316 3.1754384  2.3312886  1.0489001  0.         1.6321547\n",
      "  1.3033621 ]\n",
      " [3.835117   0.         3.3978534  0.         0.         3.5281527\n",
      "  0.        ]\n",
      " [0.         0.         1.8323454  0.76151496 0.         0.\n",
      "  0.1361357 ]\n",
      " [0.         0.         0.9155458  1.531595   0.         0.\n",
      "  0.        ]\n",
      " [0.         0.28093386 0.         1.9003613  0.         5.9696755\n",
      "  0.        ]\n",
      " [0.         0.8161071  2.7905605  0.01971716 0.         3.1926236\n",
      "  0.        ]]\n",
      "\n",
      "[[0.         5.2830772  5.197967   0.         0.         4.573313\n",
      "  1.1360624 ]\n",
      " [1.0654786  0.         5.575427   0.         2.4512787  0.\n",
      "  0.        ]\n",
      " [1.4754058  2.7058415  1.3605483  0.         0.         1.0877504\n",
      "  1.5896249 ]\n",
      " [1.0673223  3.5350022  1.1148915  0.         1.929975   0.\n",
      "  0.        ]\n",
      " [0.26214316 3.1754384  2.3312886  1.0489001  0.         1.6321547\n",
      "  1.3033621 ]\n",
      " [3.835117   0.         3.3978534  0.         0.         3.5281527\n",
      "  0.        ]\n",
      " [0.         0.         1.8323454  0.76151496 0.         0.\n",
      "  0.1361357 ]\n",
      " [0.         0.         0.9155458  1.531595   0.         0.\n",
      "  0.        ]\n",
      " [0.         0.28093386 0.         1.9003613  0.         5.9696755\n",
      "  0.        ]\n",
      " [0.         0.8161071  2.7905605  0.01971716 0.         3.1926236\n",
      "  0.        ]]\n",
      "[[ 3.845357    6.6285257   0.37037545  0.          0.          3.245362\n",
      "   6.1868515   0.          8.247099    0.         17.078712  ]\n",
      " [ 1.4818311   3.554914    3.3111033   2.5407841   0.          0.\n",
      "   0.          0.          8.988222    3.9863656   7.9463983 ]\n",
      " [ 0.8640401   0.          7.1841216   0.          0.          0.68663836\n",
      "   2.6233687   0.          2.952598    0.          8.464328  ]\n",
      " [ 2.1443465   0.          7.3255634   1.209481    0.          4.160841\n",
      "   0.26841575  0.          0.          2.9542108   6.1194744 ]\n",
      " [ 1.8095214   2.7654958   1.3211942   0.          0.          2.8717456\n",
      "   1.9303885   0.          2.0640912   0.          9.062479  ]\n",
      " [ 6.107601    0.         13.744531    0.          0.          0.\n",
      "   1.4401295   0.21853954 12.107409    1.5768355  15.117763  ]\n",
      " [ 1.4678043   2.6702785   0.          1.5422316   0.          0.17157328\n",
      "   0.          0.03738528  3.0990803   0.          3.324399  ]\n",
      " [ 2.2080975   1.9758414   0.          2.4842632   0.          1.1234448\n",
      "   0.          0.          0.33587736  0.          2.3172777 ]\n",
      " [ 7.388787    0.          1.3749593   0.          5.3115153   1.9239028\n",
      "   2.749527    0.          2.6821518   0.          5.8795147 ]\n",
      " [ 3.877511    2.2230797   0.          0.          0.          0.02982622\n",
      "   1.6348608   1.084573    7.3920918   0.09922177  7.833666  ]]\n",
      "Expert 1:\n",
      "Expert 1 gets 10.0 tokens\n",
      "  (10, 11) * (11, 7) + (1, 7) = (10, 7)\n",
      "\n",
      "  (10, 7) * (7, 11) + (1, 11) = (10, 11)\n",
      "\n",
      "input = [[ 1.6243454  -0.6117564  -0.5281718  -1.0729686   0.86540765 -2.3015387\n",
      "   1.7448118  -0.7612069   0.3190391  -0.24937038  1.4621079 ]\n",
      " [-0.84520566 -0.6712461  -0.0126646  -1.1173104   0.2344157   1.6598022\n",
      "   0.74204415 -0.19183555 -0.887629   -0.7471583   1.6924546 ]\n",
      " [ 0.05080776 -0.6369957   0.19091548  2.1002553   0.12015896  0.6172031\n",
      "   0.30017033 -0.35224986 -1.1425182  -0.34934273 -0.20889424]\n",
      " [ 0.5866232   0.8389834   0.9311021   0.2855873   0.8851412  -0.7543979\n",
      "   1.2528682   0.5129298  -0.29809284  0.48851815 -0.07557172]\n",
      " [ 1.1316293   1.5198169   2.1855755  -1.3964963  -1.4441139  -0.5044659\n",
      "   0.16003707  0.8761689   0.31563494 -2.0222013  -0.30620402]\n",
      " [ 0.8279746   0.23009473  0.7620112  -0.22232814 -0.20075807  0.18656139\n",
      "   0.41005164  0.19829972  0.11900865 -0.6706623   0.37756377]\n",
      " [ 0.698032   -0.44712856  1.2245077   0.40349165  0.5935785  -1.0949118\n",
      "   0.16938244  0.7405565  -0.9537006  -0.2662185   0.03261455]\n",
      " [-1.3731173   0.31515938  0.84616065 -0.85951596  0.35054597 -1.3122834\n",
      "  -0.03869551 -1.6157724   1.1214178   0.40890053 -0.02461696]\n",
      " [-0.7751616   1.2737559   1.9671017  -1.8579819   1.236164    1.6276507\n",
      "   0.33801168 -1.199268    0.8633453  -0.1809203  -0.60392064]\n",
      " [-1.2300582   0.55053747  0.79280686 -0.62353075  0.52057636 -1.1443413\n",
      "   0.80186105  0.0465673  -0.18656977 -0.10174587  0.8688862 ]]\n",
      "\n",
      "w1 = [[ 1.61694956e+00  5.02740860e-01  1.55880558e+00  1.09402694e-01\n",
      "  -1.21974444e+00  2.44936872e+00 -5.45774162e-01]\n",
      " [-1.98837861e-01 -7.00398505e-01 -2.03394443e-01  2.42669448e-01\n",
      "   2.01830178e-01  6.61020279e-01  1.79215825e+00]\n",
      " [-1.20464571e-01 -1.23312068e+00 -1.18231809e+00 -6.65754497e-01\n",
      "  -1.67419577e+00  8.25029850e-01 -4.98213559e-01]\n",
      " [-3.10984969e-01 -1.89148285e-03 -1.39662039e+00 -8.61316383e-01\n",
      "   6.74711525e-01  6.18539155e-01 -4.43171918e-01]\n",
      " [ 1.81053495e+00 -1.30572689e+00 -3.44987214e-01 -2.30839744e-01\n",
      "  -2.79308510e+00  1.93752885e+00  3.66332024e-01]\n",
      " [-1.04458940e+00  2.05117345e+00  5.85662007e-01  4.29526150e-01\n",
      "  -6.06998384e-01  1.06222726e-01 -1.52568030e+00]\n",
      " [ 7.95026124e-01 -3.74438316e-01  1.34048194e-01  1.20205486e+00\n",
      "   2.84748107e-01  2.62467444e-01  2.76499301e-01]\n",
      " [-7.33271599e-01  8.36004734e-01  1.54335916e+00  7.58805633e-01\n",
      "   8.84908795e-01 -8.77281547e-01 -8.67787242e-01]\n",
      " [-1.44087601e+00  1.23225307e+00 -2.54179865e-01  1.39984393e+00\n",
      "  -7.81911671e-01 -4.37508970e-01  9.54250842e-02]\n",
      " [ 9.21450078e-01  6.07501976e-02  2.11124748e-01  1.65275671e-02\n",
      "   1.77187726e-01 -1.11646998e+00  8.09271038e-02]\n",
      " [-1.86578989e-01 -5.68244793e-02  4.92336541e-01 -6.80678129e-01\n",
      "  -8.45080242e-02 -2.97361881e-01  4.17302012e-01]]\n",
      "\n",
      "b1 = [[-0.39181623  0.6840013  -0.35340998 -1.7879128   0.3618473  -0.42449278\n",
      "  -0.73153096]]\n",
      "\n",
      "output1 = [[7.707691   0.         2.4247558  0.         0.         4.312396\n",
      "  3.6160786 ]\n",
      " [0.         2.1718402  1.6367807  0.         0.         0.\n",
      "  0.        ]\n",
      " [0.57391655 0.20129502 0.         0.         1.1813571  2.3736775\n",
      "  0.        ]\n",
      " [4.0932455  0.         0.         0.         0.         3.6329627\n",
      "  1.2175257 ]\n",
      " [0.         0.         1.3863176  0.04320884 0.         2.9237392\n",
      "  0.16785133]\n",
      " [0.         0.74136525 0.8535905  0.         0.         2.3957198\n",
      "  0.        ]\n",
      " [3.4856174  0.         0.         0.         0.         3.3828454\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  4.1938596 ]\n",
      " [0.         0.         0.         0.25378156 0.         2.7051754\n",
      "  0.7371406 ]\n",
      " [0.36237428 0.         0.         0.         0.         0.\n",
      "  3.2622542 ]]\n",
      "\n",
      "[[7.707691   0.         2.4247558  0.         0.         4.312396\n",
      "  3.6160786 ]\n",
      " [0.         2.1718402  1.6367807  0.         0.         0.\n",
      "  0.        ]\n",
      " [0.57391655 0.20129502 0.         0.         1.1813571  2.3736775\n",
      "  0.        ]\n",
      " [4.0932455  0.         0.         0.         0.         3.6329627\n",
      "  1.2175257 ]\n",
      " [0.         0.         1.3863176  0.04320884 0.         2.9237392\n",
      "  0.16785133]\n",
      " [0.         0.74136525 0.8535905  0.         0.         2.3957198\n",
      "  0.        ]\n",
      " [3.4856174  0.         0.         0.         0.         3.3828454\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  4.1938596 ]\n",
      " [0.         0.         0.         0.25378156 0.         2.7051754\n",
      "  0.7371406 ]\n",
      " [0.36237428 0.         0.         0.         0.         0.\n",
      "  3.2622542 ]]\n",
      "[[ 2.1662235  15.087415    0.          0.          0.          0.\n",
      "   0.          0.          0.          2.6101222  10.101072  ]\n",
      " [ 2.3421009   1.9218526   4.2821555   0.          0.          3.2312937\n",
      "   0.          0.          0.          0.2336668   0.        ]\n",
      " [ 3.8279788   1.8096243   3.5940287   0.          0.          0.\n",
      "   0.8024425   0.          1.6437588   0.          0.        ]\n",
      " [ 3.0365274   9.775187    0.06616327  0.          0.          0.\n",
      "   0.          0.          2.8769152   0.          4.6649427 ]\n",
      " [ 0.          1.9033972   5.0389094   0.          0.          0.\n",
      "   2.2125123   0.10192598  0.95973986  0.          0.        ]\n",
      " [ 1.0907216   2.875792    4.9617877   0.          0.          0.\n",
      "   2.1404717   0.          0.20911479  0.          0.        ]\n",
      " [ 4.1130495   7.283635    0.8665309   0.          0.          0.\n",
      "   0.          0.          2.4730213   0.          4.1598573 ]\n",
      " [ 0.          5.5667048   0.          0.          0.          0.\n",
      "   0.          0.27219707  0.55355614  6.600869    0.        ]\n",
      " [ 0.          3.591499    3.670706    0.          0.          0.\n",
      "   3.4788866   0.          3.2247522   0.          0.        ]\n",
      " [ 0.          4.74145     0.          0.          0.          0.\n",
      "   0.          0.          0.10074252  5.1448936   0.        ]]\n",
      "Expert 2:\n",
      "Expert 2 gets 9.0 tokens\n",
      "  (9, 11) * (11, 7) + (1, 7) = (9, 7)\n",
      "\n",
      "  (9, 7) * (7, 11) + (1, 11) = (9, 11)\n",
      "\n",
      "input = [[-2.0601406  -0.3224172  -0.38405436  1.1337694  -1.0998913  -0.1724282\n",
      "  -0.8778584   0.04221375  0.58281523 -1.1006192   1.1447237 ]\n",
      " [ 0.9015907   0.50249434  0.90085596 -0.68372786 -0.12289023 -0.93576944\n",
      "  -0.26788807  0.53035545 -0.69166076 -0.39675352 -0.6871727 ]\n",
      " [-0.84520566 -0.6712461  -0.0126646  -1.1173104   0.2344157   1.6598022\n",
      "   0.74204415 -0.19183555 -0.887629   -0.7471583   1.6924546 ]\n",
      " [ 0.05080776 -0.6369957   0.19091548  2.1002553   0.12015896  0.6172031\n",
      "   0.30017033 -0.35224986 -1.1425182  -0.34934273 -0.20889424]\n",
      " [ 0.8279746   0.23009473  0.7620112  -0.22232814 -0.20075807  0.18656139\n",
      "   0.41005164  0.19829972  0.11900865 -0.6706623   0.37756377]\n",
      " [ 0.12182127  1.1294839   1.1989179   0.18515642 -0.37528494 -0.6387304\n",
      "   0.42349437  0.07734007 -0.34385368  0.04359686 -0.62000084]\n",
      " [ 0.698032   -0.44712856  1.2245077   0.40349165  0.5935785  -1.0949118\n",
      "   0.16938244  0.7405565  -0.9537006  -0.2662185   0.03261455]\n",
      " [-0.7751616   1.2737559   1.9671017  -1.8579819   1.236164    1.6276507\n",
      "   0.33801168 -1.199268    0.8633453  -0.1809203  -0.60392064]\n",
      " [-1.2300582   0.55053747  0.79280686 -0.62353075  0.52057636 -1.1443413\n",
      "   0.80186105  0.0465673  -0.18656977 -0.10174587  0.8688862 ]]\n",
      "\n",
      "w1 = [[ 0.78477067 -0.95542526  0.58591044  2.0657833  -1.471157   -0.8301719\n",
      "  -0.8805776 ]\n",
      " [-0.27909774  1.6228491   0.01335268 -0.6946936   0.6218035  -0.5998045\n",
      "   1.1234121 ]\n",
      " [ 0.30526704  1.3887794  -0.66134423  3.030857    0.8245846   0.6545802\n",
      "  -0.05118845]\n",
      " [-0.72559714 -0.8677687  -0.13597733 -0.79726976  0.2826757  -0.8260974\n",
      "   0.6210827 ]\n",
      " [ 0.9561217  -0.7058405   1.1926861  -0.23794194  1.1552879   0.43816635\n",
      "   1.1223283 ]\n",
      " [-0.99701977 -0.10679398  1.4514292  -0.61803687 -2.0372012  -1.9425892\n",
      "  -2.5064406 ]\n",
      " [-2.1141639  -0.41163915  1.2785281  -0.44222927  0.32352737 -0.10999149\n",
      "   0.00854895]\n",
      " [-0.16819884 -0.17418034  0.4611641  -1.1759827   1.0101272   0.92001796\n",
      "  -0.19505735]\n",
      " [ 0.8053934  -0.70134443 -0.53722304  0.15626384 -0.19022103 -0.44873804\n",
      "  -0.67244804]\n",
      " [-0.5574947   0.93916875 -1.9433234   0.35249436 -0.23643695  0.7278135\n",
      "   0.5150736 ]\n",
      " [-2.7825344   0.5846466   0.32427424  0.02186284 -0.46867383  0.8532812\n",
      "  -0.4130293 ]]\n",
      "\n",
      "b1 = [[-1.5657382   1.0138224  -2.2271125  -1.6993335  -0.27584606  1.2289556\n",
      "   1.3097059 ]]\n",
      "\n",
      "output1 = [[0.         1.3172895  0.         0.         1.010339   1.8472259\n",
      "  1.2358216 ]\n",
      " [2.6415186  2.727592   0.         2.9289603  2.0206537  3.050222\n",
      "  3.255887  ]\n",
      " [0.         1.979557   3.4555852  0.         0.         1.1669049\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.1777928 ]\n",
      " [0.         1.2732149  0.         1.6464189  0.         0.5536515\n",
      "  0.        ]\n",
      " [0.         4.299702   0.         1.4077102  2.7166755  1.8401067\n",
      "  4.2029753 ]\n",
      " [0.         0.9088763  0.         2.7903976  3.4912186  4.697652\n",
      "  4.138886  ]\n",
      " [0.94192433 6.0606084  0.         3.2764869  0.         0.\n",
      "  0.        ]\n",
      " [0.         4.684466   0.         0.         5.245023   6.110756\n",
      "  5.7479305 ]]\n",
      "\n",
      "[[0.         1.3172895  0.         0.         1.010339   1.8472259\n",
      "  1.2358216 ]\n",
      " [2.6415186  2.727592   0.         2.9289603  2.0206537  3.050222\n",
      "  3.255887  ]\n",
      " [0.         1.979557   3.4555852  0.         0.         1.1669049\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.1777928 ]\n",
      " [0.         1.2732149  0.         1.6464189  0.         0.5536515\n",
      "  0.        ]\n",
      " [0.         4.299702   0.         1.4077102  2.7166755  1.8401067\n",
      "  4.2029753 ]\n",
      " [0.         0.9088763  0.         2.7903976  3.4912186  4.697652\n",
      "  4.138886  ]\n",
      " [0.94192433 6.0606084  0.         3.2764869  0.         0.\n",
      "  0.        ]\n",
      " [0.         4.684466   0.         0.         5.245023   6.110756\n",
      "  5.7479305 ]]\n",
      "[[ 1.160926    1.9430139   1.6612518   0.          2.407128    0.\n",
      "   0.          0.          2.2939105   0.          0.        ]\n",
      " [ 8.612797    5.7203336   5.3426676   0.          8.488624    0.\n",
      "   0.          0.          4.6948676   0.          0.        ]\n",
      " [ 0.          2.418865    5.7680454   0.          4.9138293   0.\n",
      "   0.          0.          2.0616095   0.          0.        ]\n",
      " [ 0.70657235  1.4149595   0.          0.          1.5143119   0.\n",
      "   0.          0.          0.8199151   0.27350503  0.6381367 ]\n",
      " [ 2.997957    1.3687508   3.0921142   0.          6.181672    0.\n",
      "   0.          0.          1.2486453   0.          0.        ]\n",
      " [ 2.4545896   6.8243403   3.4993007   0.         10.083919    0.\n",
      "   0.          0.          3.967732    0.          0.        ]\n",
      " [ 6.8416038   2.6171346   6.4059687   0.          0.          0.\n",
      "   1.2814233   0.          4.0533957   0.          3.491967  ]\n",
      " [ 5.089412    6.632255    9.072102    0.         24.410017    0.\n",
      "   0.          0.          3.1524081   0.          0.        ]\n",
      " [ 2.1925137   6.76238     7.7640324   0.          2.1880143   0.\n",
      "   5.0713754   0.          6.7193146   0.          0.        ]]\n",
      "Expert 3:\n",
      "Expert 3 gets 12.0 tokens\n",
      "  (12, 11) * (11, 7) + (1, 7) = (12, 7)\n",
      "\n",
      "  (12, 7) * (7, 11) + (1, 11) = (12, 11)\n",
      "\n",
      "input = [[ 1.6243454  -0.6117564  -0.5281718  -1.0729686   0.86540765 -2.3015387\n",
      "   1.7448118  -0.7612069   0.3190391  -0.24937038  1.4621079 ]\n",
      " [-2.0601406  -0.3224172  -0.38405436  1.1337694  -1.0998913  -0.1724282\n",
      "  -0.8778584   0.04221375  0.58281523 -1.1006192   1.1447237 ]\n",
      " [ 0.9015907   0.50249434  0.90085596 -0.68372786 -0.12289023 -0.93576944\n",
      "  -0.26788807  0.53035545 -0.69166076 -0.39675352 -0.6871727 ]\n",
      " [-0.84520566 -0.6712461  -0.0126646  -1.1173104   0.2344157   1.6598022\n",
      "   0.74204415 -0.19183555 -0.887629   -0.7471583   1.6924546 ]\n",
      " [ 0.5866232   0.8389834   0.9311021   0.2855873   0.8851412  -0.7543979\n",
      "   1.2528682   0.5129298  -0.29809284  0.48851815 -0.07557172]\n",
      " [ 1.1316293   1.5198169   2.1855755  -1.3964963  -1.4441139  -0.5044659\n",
      "   0.16003707  0.8761689   0.31563494 -2.0222013  -0.30620402]\n",
      " [ 0.8279746   0.23009473  0.7620112  -0.22232814 -0.20075807  0.18656139\n",
      "   0.41005164  0.19829972  0.11900865 -0.6706623   0.37756377]\n",
      " [ 0.12182127  1.1294839   1.1989179   0.18515642 -0.37528494 -0.6387304\n",
      "   0.42349437  0.07734007 -0.34385368  0.04359686 -0.62000084]\n",
      " [ 0.698032   -0.44712856  1.2245077   0.40349165  0.5935785  -1.0949118\n",
      "   0.16938244  0.7405565  -0.9537006  -0.2662185   0.03261455]\n",
      " [-1.3731173   0.31515938  0.84616065 -0.85951596  0.35054597 -1.3122834\n",
      "  -0.03869551 -1.6157724   1.1214178   0.40890053 -0.02461696]\n",
      " [-0.7751616   1.2737559   1.9671017  -1.8579819   1.236164    1.6276507\n",
      "   0.33801168 -1.199268    0.8633453  -0.1809203  -0.60392064]\n",
      " [-1.2300582   0.55053747  0.79280686 -0.62353075  0.52057636 -1.1443413\n",
      "   0.80186105  0.0465673  -0.18656977 -0.10174587  0.8688862 ]]\n",
      "\n",
      "w1 = [[ 1.8347176   0.56438285  2.137828   -0.785534   -1.7559257   0.71478957\n",
      "   0.85270405]\n",
      " [ 0.0353601  -1.5387932  -0.4478952   0.61798555 -0.18417633 -0.11598518\n",
      "  -0.17545897]\n",
      " [-0.93391466 -0.5330203  -1.4265554   1.76796    -0.47537288  0.47761017\n",
      "  -1.021886  ]\n",
      " [ 0.79452825 -1.873161    0.92061514 -0.03536792  2.110605   -1.306534\n",
      "   0.07638048]\n",
      " [ 0.36723182  1.2328992  -0.42285696  0.08646441 -2.1424668  -0.83016884\n",
      "   0.45161596]\n",
      " [ 1.1041744  -0.28173625  2.0563555   1.7602493  -0.06065249 -2.413503\n",
      "  -1.7775664 ]\n",
      " [-0.77785885  1.1158412   0.31027228 -2.0942478  -0.22876583  1.6133614\n",
      "  -0.37480468]\n",
      " [-0.7499696   2.054624    0.05340954 -0.4791571   0.35016716  0.01716473\n",
      "  -0.42914227]\n",
      " [ 1.2084563   1.1157018   0.84086156 -0.10288722  1.1469004  -0.04970258\n",
      "   0.46664327]\n",
      " [ 1.0336869   0.8088444   1.7897546   0.45128402 -1.68406    -1.1601701\n",
      "   1.3501068 ]\n",
      " [-0.33128318  0.38653913 -0.8514556   1.0008814  -0.38483226  1.4581082\n",
      "  -0.532234  ]]\n",
      "\n",
      "b1 = [[-1.1549827  -0.1776322  -1.5104563   1.0112071  -1.4765626  -0.14319575\n",
      "   1.0329838 ]]\n",
      "\n",
      "output1 = [[ 0.          6.789595    0.          0.          0.         12.282082\n",
      "   6.171875  ]\n",
      " [ 0.          0.          0.          3.7198615   9.439739    0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.083794    0.          3.1966534\n",
      "   1.7288303 ]\n",
      " [ 0.          1.7926836   0.          4.205372    0.          1.1563505\n",
      "   0.        ]\n",
      " [ 0.          1.6202304   0.          0.          0.          2.7042994\n",
      "   2.0680318 ]\n",
      " [ 0.          0.          0.          1.955534    0.          7.9313836\n",
      "   0.        ]\n",
      " [ 0.          0.24705146  0.          1.2783312   0.          2.7804255\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          1.080379    0.          1.7437665\n",
      "   0.73004067]\n",
      " [ 0.          0.97997093  0.          0.          0.          3.3048773\n",
      "   1.4974015 ]\n",
      " [ 0.          0.          0.          2.4311016   0.          2.5858803\n",
      "   3.1638398 ]\n",
      " [ 0.          0.          0.          8.014542    0.          0.\n",
      "   0.        ]\n",
      " [ 0.          1.0264263   0.          0.9133954   0.          5.125476\n",
      "   0.29156572]]\n",
      "\n",
      "[[ 0.          6.789595    0.          0.          0.         12.282082\n",
      "   6.171875  ]\n",
      " [ 0.          0.          0.          3.7198615   9.439739    0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.083794    0.          3.1966534\n",
      "   1.7288303 ]\n",
      " [ 0.          1.7926836   0.          4.205372    0.          1.1563505\n",
      "   0.        ]\n",
      " [ 0.          1.6202304   0.          0.          0.          2.7042994\n",
      "   2.0680318 ]\n",
      " [ 0.          0.          0.          1.955534    0.          7.9313836\n",
      "   0.        ]\n",
      " [ 0.          0.24705146  0.          1.2783312   0.          2.7804255\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          1.080379    0.          1.7437665\n",
      "   0.73004067]\n",
      " [ 0.          0.97997093  0.          0.          0.          3.3048773\n",
      "   1.4974015 ]\n",
      " [ 0.          0.          0.          2.4311016   0.          2.5858803\n",
      "   3.1638398 ]\n",
      " [ 0.          0.          0.          8.014542    0.          0.\n",
      "   0.        ]\n",
      " [ 0.          1.0264263   0.          0.9133954   0.          5.125476\n",
      "   0.29156572]]\n",
      "[[ 3.9200153   2.55085     9.684633    0.         19.849977    2.3176398\n",
      "  25.194727   11.11215     2.858234   24.544346    3.8041286 ]\n",
      " [ 4.45353     6.9576325  11.834846    6.7389917   7.5624228   0.\n",
      "   7.0750117  20.562122    0.          0.          0.        ]\n",
      " [ 0.6392781   2.1484048   0.          0.          2.2388732   1.7084259\n",
      "   9.165665    2.221799    1.5692018   2.2585325   0.61294174]\n",
      " [ 1.7070558   0.          0.19002917  0.76736736  6.170456    0.\n",
      "   2.31044     0.23695827  2.8419175   3.3133845   0.6965139 ]\n",
      " [ 0.          0.72551525  2.6704814   0.          4.0226693   0.3329399\n",
      "   6.3301334   1.8651778   0.55681264  5.8984556   1.5265249 ]\n",
      " [ 8.022174    4.302322    0.          0.          9.122308    5.462567\n",
      "  20.416817    7.1520505   4.1873274   4.1792793   0.        ]\n",
      " [ 2.3928773   1.424733    0.          0.          3.7775056   1.8822546\n",
      "   7.5673585   2.1063948   1.6069902   1.9000897   0.        ]\n",
      " [ 0.58849305  1.196496    0.          0.          1.8237494   1.0633025\n",
      "   5.483446    0.8708104   1.5233235   0.83070767  0.24583411]\n",
      " [ 0.7046024   1.4263649   0.9186016   0.          3.9479504   1.312012\n",
      "   8.317104    2.5331278   0.87578917  4.6813474   0.5547434 ]\n",
      " [ 0.          2.032838    0.          0.          2.1980932   0.68129975\n",
      "   8.327135    0.8805013   4.140929    0.9952756   2.783181  ]\n",
      " [ 2.6969683   0.03236823  0.          0.99319434  4.3617253   0.\n",
      "   1.8333033   0.          6.930067    0.          1.366833  ]\n",
      " [ 4.150155    2.122994    0.          0.          7.0603814   2.921775\n",
      "  12.472104    4.5468326   1.7928272   5.3929944   0.        ]]\n",
      "Expert 4:\n",
      "Expert 4 gets 11.0 tokens\n",
      "  (11, 11) * (11, 7) + (1, 7) = (11, 7)\n",
      "\n",
      "  (11, 7) * (7, 11) + (1, 11) = (11, 11)\n",
      "\n",
      "input = [[ 1.6243454  -0.6117564  -0.5281718  -1.0729686   0.86540765 -2.3015387\n",
      "   1.7448118  -0.7612069   0.3190391  -0.24937038  1.4621079 ]\n",
      " [-2.0601406  -0.3224172  -0.38405436  1.1337694  -1.0998913  -0.1724282\n",
      "  -0.8778584   0.04221375  0.58281523 -1.1006192   1.1447237 ]\n",
      " [ 0.9015907   0.50249434  0.90085596 -0.68372786 -0.12289023 -0.93576944\n",
      "  -0.26788807  0.53035545 -0.69166076 -0.39675352 -0.6871727 ]\n",
      " [-0.84520566 -0.6712461  -0.0126646  -1.1173104   0.2344157   1.6598022\n",
      "   0.74204415 -0.19183555 -0.887629   -0.7471583   1.6924546 ]\n",
      " [ 0.05080776 -0.6369957   0.19091548  2.1002553   0.12015896  0.6172031\n",
      "   0.30017033 -0.35224986 -1.1425182  -0.34934273 -0.20889424]\n",
      " [ 0.5866232   0.8389834   0.9311021   0.2855873   0.8851412  -0.7543979\n",
      "   1.2528682   0.5129298  -0.29809284  0.48851815 -0.07557172]\n",
      " [ 1.1316293   1.5198169   2.1855755  -1.3964963  -1.4441139  -0.5044659\n",
      "   0.16003707  0.8761689   0.31563494 -2.0222013  -0.30620402]\n",
      " [ 0.8279746   0.23009473  0.7620112  -0.22232814 -0.20075807  0.18656139\n",
      "   0.41005164  0.19829972  0.11900865 -0.6706623   0.37756377]\n",
      " [ 0.12182127  1.1294839   1.1989179   0.18515642 -0.37528494 -0.6387304\n",
      "   0.42349437  0.07734007 -0.34385368  0.04359686 -0.62000084]\n",
      " [ 0.698032   -0.44712856  1.2245077   0.40349165  0.5935785  -1.0949118\n",
      "   0.16938244  0.7405565  -0.9537006  -0.2662185   0.03261455]\n",
      " [-1.3731173   0.31515938  0.84616065 -0.85951596  0.35054597 -1.3122834\n",
      "  -0.03869551 -1.6157724   1.1214178   0.40890053 -0.02461696]]\n",
      "\n",
      "w1 = [[ 1.1181334   0.6743961  -0.7223919   1.0989963  -0.9016345  -0.8224672\n",
      "   0.7217113 ]\n",
      " [-0.625342   -0.59384304 -0.3439007  -1.0001692   1.0449944   0.6085147\n",
      "  -0.0693287 ]\n",
      " [-0.10839207  0.45015553  1.7653351   0.87096983 -0.5084571   0.7774192\n",
      "  -0.11877117]\n",
      " [-0.19899818  1.8664714  -0.4189379  -0.47918493 -1.9521053  -1.4023291\n",
      "   0.45112294]\n",
      " [-0.6949209   0.5154138  -1.114871   -0.76730984  0.6745707   1.4608924\n",
      "   0.5924728 ]\n",
      " [ 1.1978308   1.7045941   1.0400891  -0.91844004 -0.10534471  0.6301957\n",
      "  -0.4148469 ]\n",
      " [ 0.45194605 -1.5791563  -0.828628    0.52887976 -2.2370865  -1.1077125\n",
      "  -0.01771832]\n",
      " [-1.7193944   0.057121   -0.7995475  -0.2915946  -0.25898287  0.18929319\n",
      "  -0.5637887 ]\n",
      " [ 0.08968641 -0.6011568   0.5560735   1.6938092   0.19686978  0.16986926\n",
      "  -1.164008  ]\n",
      " [ 0.6933662  -0.7580673  -0.8088472   0.55743945  0.18103874  1.1071755\n",
      "   1.4428769 ]\n",
      " [-0.53968155  0.12837699  1.7604152   0.96653926  0.71304905  1.3062061\n",
      "  -0.604603  ]]\n",
      "\n",
      "b1 = [[-0.22241403  1.4701604  -0.87000823  0.36919048  0.8532822  -0.13971174\n",
      "   1.3863143 ]]\n",
      "\n",
      "output1 = [[0.0529141  0.         0.         7.229445   0.         0.\n",
      "  2.4303179 ]\n",
      " [0.         3.374343   4.5462084  0.         2.3167405  0.\n",
      "  0.        ]\n",
      " [0.         0.3323841  0.         0.57023346 1.221776   0.\n",
      "  2.2559528 ]\n",
      " [0.45542473 2.2922642  4.510804   0.         2.3711822  3.4668202\n",
      "  0.        ]\n",
      " [0.959262   7.4334245  0.         0.         0.         0.\n",
      "  3.352505  ]\n",
      " [0.         0.         0.         1.0699791  0.         0.13019332\n",
      "  3.393312  ]\n",
      " [0.         0.         3.757447   3.1774943  1.0077626  0.\n",
      "  0.        ]\n",
      " [0.07037161 1.8836217  1.083926   2.1536205  0.         0.\n",
      "  0.12722945]\n",
      " [0.         0.         0.         0.24753982 0.         0.\n",
      "  2.1665897 ]\n",
      " [0.         2.5044594  0.         1.1482198  0.         0.\n",
      "  3.0493357 ]\n",
      " [0.         0.         1.6851401  3.1843476  4.8252807  3.077745\n",
      "  0.84848624]]\n",
      "\n",
      "[[0.0529141  0.         0.         7.229445   0.         0.\n",
      "  2.4303179 ]\n",
      " [0.         3.374343   4.5462084  0.         2.3167405  0.\n",
      "  0.        ]\n",
      " [0.         0.3323841  0.         0.57023346 1.221776   0.\n",
      "  2.2559528 ]\n",
      " [0.45542473 2.2922642  4.510804   0.         2.3711822  3.4668202\n",
      "  0.        ]\n",
      " [0.959262   7.4334245  0.         0.         0.         0.\n",
      "  3.352505  ]\n",
      " [0.         0.         0.         1.0699791  0.         0.13019332\n",
      "  3.393312  ]\n",
      " [0.         0.         3.757447   3.1774943  1.0077626  0.\n",
      "  0.        ]\n",
      " [0.07037161 1.8836217  1.083926   2.1536205  0.         0.\n",
      "  0.12722945]\n",
      " [0.         0.         0.         0.24753982 0.         0.\n",
      "  2.1665897 ]\n",
      " [0.         2.5044594  0.         1.1482198  0.         0.\n",
      "  3.0493357 ]\n",
      " [0.         0.         1.6851401  3.1843476  4.8252807  3.077745\n",
      "  0.84848624]]\n",
      "[[ 2.3411012   0.         14.163695    0.         10.286294    0.\n",
      "  13.115327    7.8975263   0.          0.          7.582478  ]\n",
      " [ 4.5116544   0.          2.029739    0.          0.         10.212342\n",
      "   0.          0.          3.5166361   0.          0.        ]\n",
      " [ 3.3956556   2.1153016   1.4709916   1.3461978   0.          3.551098\n",
      "   4.5011864   2.0928185   0.          0.          1.172797  ]\n",
      " [ 2.6578817   0.          5.240532    0.          0.         11.663737\n",
      "   0.          0.          2.679147    0.          0.19304082]\n",
      " [ 2.6345294   6.0109115   0.          0.8058377   0.         16.324886\n",
      "   7.510905    0.          0.          0.          0.        ]\n",
      " [ 3.5324943   2.854776    1.8642116   2.8002589   0.          2.7315137\n",
      "   7.6322994   1.4308486   0.          0.          3.6125462 ]\n",
      " [ 2.779762    0.          9.881955    0.          0.          1.3415931\n",
      "   0.          2.9248743   0.          0.09726143  5.5446525 ]\n",
      " [ 1.0069534   0.          4.656739    0.          0.          2.8657863\n",
      "   1.8669876   0.          0.          0.          0.        ]\n",
      " [ 2.4344673   2.5174212   0.77730465  2.0496054   0.          1.844439\n",
      "   4.568339    0.38146466  0.          0.          2.0837274 ]\n",
      " [ 3.4781432   2.7869194   0.18370926  1.5344824   0.          6.533671\n",
      "   7.8166237   0.          0.          0.          0.        ]\n",
      " [ 4.385604    0.         11.004646    0.          0.19810462  7.5136127\n",
      "   0.          9.185559    0.          0.          6.8008575 ]]\n",
      "Total output: (13, 11)\n"
     ]
    }
   ],
   "source": [
    "# words(7) * emb_size(4)\n",
    "total_output = b * words # … so that if a word doesn't go through any expert it will still have some value\n",
    "\n",
    "# Repeat for every expert, looking at routed do determine which words go to said expert\n",
    "for n, expert_w1, expert_b1, expert_w2, expert_b2, mask in zip(count(), experts_w1, experts_b1, experts_w2, experts_b2, router):\n",
    "    print(f\"Expert {n}:\")\n",
    "    print(f\"Expert {n} gets {mask.sum()} tokens\")\n",
    "    assert mask.shape[0] == words.shape[0]\n",
    "    \n",
    "    # select all words where the mask for this expert is > 0\n",
    "    expert_input = words[mask.nonzero()]\n",
    "    \n",
    "    # classic matmul op for feed-forward I guess? + relu\n",
    "    expert_output1 = np.maximum(0.0, np.add(np.matmul(expert_input, expert_w1), expert_b1))\n",
    "    expert_output2 = np.maximum(0.0, np.add(np.matmul(expert_output1, expert_w2), expert_b2))\n",
    "    assert expert_output2.shape[0] == mask.sum()\n",
    "    \n",
    "    # TODO: no relu here yet.\n",
    "\n",
    "    # Addition for all the selected experts.\n",
    "    # TODO: after loop: normalisation? We're now summing K experts + `b` of the original input.\n",
    "    total_output[mask.nonzero()] += expert_output2\n",
    "\n",
    "    print(f\"  {expert_input.shape} * {expert_w1.shape} + {expert_b1.shape} = {expert_output1.shape}\\n\")\n",
    "    print(f\"  {expert_output1.shape} * {expert_w2.shape} + {expert_b2.shape} = {expert_output2.shape}\\n\")\n",
    "    \n",
    "    exported[f\"expert_{n}_src\"] = expert_input.astype(np.float32, order='C')\n",
    "    exported[f\"expert_{n}_dst\"] = expert_output2.astype(np.float32, order='C')\n",
    "\n",
    "    print(f\"input = {expert_input}\\n\")\n",
    "    print(f\"w1 = {expert_w1}\\n\")\n",
    "    print(f\"b1 = {expert_b1}\\n\")\n",
    "    print(f\"output1 = {expert_output1}\\n\")\n",
    "    print(expert_output1)\n",
    "    print(expert_output2)\n",
    "    \n",
    "print(f\"Total output: {total_output.shape}\")\n",
    "exported[\"dst\"] = total_output.astype(np.float32, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261b8f50-16b9-456d-be41-43a568d3b4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez(\"data.npz\", **exported)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b06da5d3-e159-4ea0-bdf7-5f6c81d38e5f",
   "metadata": {},
   "source": [
    "# Do grid search generation for various variable values. Save them to separate files.\n",
    "# Do not run automatically LOL\n",
    "\n",
    "expert_num_list = [8, 16, 32, 64, 128, 256] # number of experts\n",
    "expert_dim_list = [256, 512, 1024, 2048, 4096]\n",
    "emb_dim_list = [256, 512, 1024, 2048, 4096] # embedding size\n",
    "token_num_list = [128, 256, 512, 1024, 2048, 4096, 8192] # think token count, from unrolled batches possibly\n",
    "\n",
    "\n",
    "for expert_num in expert_num_list:\n",
    "    for expert_dim in expert_dim_list:\n",
    "        for emb_dim in emb_dim_list:\n",
    "            for token_num in token_num_list:\n",
    "                \n",
    "                exported = dict()\n",
    "                \n",
    "                # Generate input\n",
    "                words = randn(token_num, emb_dim).astype(np.float32)\n",
    "                exported[\"src\"] = words\n",
    "                \n",
    "                # Generate parameters\n",
    "                experts_w1 = randn(expert_num, emb_dim, expert_dim).astype(np.float32)\n",
    "                exported[\"experts_w1\"] = experts_w1\n",
    "\n",
    "                # expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "                experts_b1 = randn(expert_num, 1, expert_dim).astype(np.float32)\n",
    "                exported[\"experts_b1\"] = experts_b1\n",
    "\n",
    "                # expert (3) * emb_size (5) * emb_size (5)\n",
    "                experts_w2 = randn(expert_num, expert_dim, emb_dim).astype(np.float32)\n",
    "                exported[\"experts_w2\"] = experts_w2\n",
    "\n",
    "                # expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "                experts_b2 = randn(expert_num, 1, emb_dim).astype(np.float32)\n",
    "                exported[\"experts_b2\"] = experts_b2\n",
    "\n",
    "                b = 0.1\n",
    "\n",
    "                # words(7) * emb_size(4)\n",
    "                total_output = b * words # … so that if a word doesn't go through any expert it will still have some value\n",
    "\n",
    "                # Repeat for every expert, looking at routed do determine which words go to said expert\n",
    "                for n, expert_w1, expert_b1, expert_w2, expert_b2, mask in zip(count(), experts_w1, experts_b1, experts_w2, experts_b2, router):\n",
    "                    #print(f\"Expert {n}:\")\n",
    "\n",
    "                    # select all words where the mask for this expert is > 0\n",
    "                    expert_input = words[mask.nonzero()]\n",
    "\n",
    "                    # classic matmul op for feed-forward I guess? + relu\n",
    "                    expert_output1 = np.maximum(0.0, np.add(np.matmul(expert_input, expert_w1), expert_b1))\n",
    "                    expert_output2 = np.maximum(0.0, np.add(np.matmul(expert_output1, expert_w2), expert_b2))\n",
    "\n",
    "                    # I did assignment here, but could also be addition\n",
    "                    total_output[mask.nonzero()] = expert_output2\n",
    "\n",
    "                    #print(f\"  {expert_input.shape} * {expert_w1.shape} + {expert_b1.shape} = {expert_output1.shape}\\n\")\n",
    "                    #print(f\"  {expert_output1.shape} * {expert_w2.shape} + {expert_b2.shape} = {expert_output2.shape}\\n\")\n",
    "\n",
    "                    exported[f\"expert_{n}_src\"] = expert_input\n",
    "                    exported[f\"expert_{n}_dst\"] = expert_output2\n",
    "\n",
    "                #print(f\"Total output: {total_output.shape}\")\n",
    "                exported[\"dst\"] = total_output\n",
    "                \n",
    "                file_name = \"exp-num_\" + str(expert_num) + \"_exp-dim_\" + str(expert_dim) + \"_emb-dim_\" + str(emb_dim) + \"_token-num_\" + str(token_num)\n",
    "                np.savez_compressed(file_name + \".npz\", **exported)\n",
    "                print(\"Finished \", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb31c3-0748-4002-815f-925ae1fb0267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e150e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
