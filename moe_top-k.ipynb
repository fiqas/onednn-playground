{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7004a127-a4dc-4522-95d8-0ec465915725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from itertools import count\n",
    "import sys\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79a0e9f-1103-4d91-b14e-b8d54a717790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#expert_num = 64 # number of experts\n",
    "#expert_dim = 512\n",
    "#emb_dim = 256 # embedding size\n",
    "#token_num = 2048 # think token count, from unrolled batches possibly\n",
    "\n",
    "expert_num = 5 # number of experts\n",
    "expert_dim = 7\n",
    "emb_dim = 11 # embedding size\n",
    "token_num = 13 # think token count, from unrolled batches possibly\n",
    "\n",
    "# Bypass weight\n",
    "b = 0.1\n",
    "\n",
    "# Export sizes and bypass weight to C++ code as well\n",
    "exported = dict(\n",
    "    expert_count=expert_num,\n",
    "    expert_size=expert_dim,\n",
    "    embedding_size=emb_dim,\n",
    "    token_count=token_num,\n",
    "    b=np.array([b], dtype=np.float32) # I don't care that those numbers are longs, but I want this multiplier to be float32.\n",
    ")\n",
    "\n",
    "# token count * embedding size. Explicitly specifying order=C so it matches the C++ implementation.\n",
    "words = randn(token_num, emb_dim).astype(np.float32, order='C')\n",
    "exported[\"src\"] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7102606e-7dbb-483f-b53a-cc993dd8d589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6243454 , -0.6117564 , -0.5281718 , -1.0729686 ,  0.86540765,\n",
       "        -2.3015387 ,  1.7448118 , -0.7612069 ,  0.3190391 , -0.24937038,\n",
       "         1.4621079 ],\n",
       "       [-2.0601406 , -0.3224172 , -0.38405436,  1.1337694 , -1.0998913 ,\n",
       "        -0.1724282 , -0.8778584 ,  0.04221375,  0.58281523, -1.1006192 ,\n",
       "         1.1447237 ],\n",
       "       [ 0.9015907 ,  0.50249434,  0.90085596, -0.68372786, -0.12289023,\n",
       "        -0.93576944, -0.26788807,  0.53035545, -0.69166076, -0.39675352,\n",
       "        -0.6871727 ],\n",
       "       [-0.84520566, -0.6712461 , -0.0126646 , -1.1173104 ,  0.2344157 ,\n",
       "         1.6598022 ,  0.74204415, -0.19183555, -0.887629  , -0.7471583 ,\n",
       "         1.6924546 ],\n",
       "       [ 0.05080776, -0.6369957 ,  0.19091548,  2.1002553 ,  0.12015896,\n",
       "         0.6172031 ,  0.30017033, -0.35224986, -1.1425182 , -0.34934273,\n",
       "        -0.20889424],\n",
       "       [ 0.5866232 ,  0.8389834 ,  0.9311021 ,  0.2855873 ,  0.8851412 ,\n",
       "        -0.7543979 ,  1.2528682 ,  0.5129298 , -0.29809284,  0.48851815,\n",
       "        -0.07557172],\n",
       "       [ 1.1316293 ,  1.5198169 ,  2.1855755 , -1.3964963 , -1.4441139 ,\n",
       "        -0.5044659 ,  0.16003707,  0.8761689 ,  0.31563494, -2.0222013 ,\n",
       "        -0.30620402],\n",
       "       [ 0.8279746 ,  0.23009473,  0.7620112 , -0.22232814, -0.20075807,\n",
       "         0.18656139,  0.41005164,  0.19829972,  0.11900865, -0.6706623 ,\n",
       "         0.37756377],\n",
       "       [ 0.12182127,  1.1294839 ,  1.1989179 ,  0.18515642, -0.37528494,\n",
       "        -0.6387304 ,  0.42349437,  0.07734007, -0.34385368,  0.04359686,\n",
       "        -0.62000084],\n",
       "       [ 0.698032  , -0.44712856,  1.2245077 ,  0.40349165,  0.5935785 ,\n",
       "        -1.0949118 ,  0.16938244,  0.7405565 , -0.9537006 , -0.2662185 ,\n",
       "         0.03261455],\n",
       "       [-1.3731173 ,  0.31515938,  0.84616065, -0.85951596,  0.35054597,\n",
       "        -1.3122834 , -0.03869551, -1.6157724 ,  1.1214178 ,  0.40890053,\n",
       "        -0.02461696],\n",
       "       [-0.7751616 ,  1.2737559 ,  1.9671017 , -1.8579819 ,  1.236164  ,\n",
       "         1.6276507 ,  0.33801168, -1.199268  ,  0.8633453 , -0.1809203 ,\n",
       "        -0.60392064],\n",
       "       [-1.2300582 ,  0.55053747,  0.79280686, -0.62353075,  0.52057636,\n",
       "        -1.1443413 ,  0.80186105,  0.0465673 , -0.18656977, -0.10174587,\n",
       "         0.8688862 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae5abfb-78af-4097-a3cd-891ee42a7133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experts_w1 = randn(expert_num, emb_dim, expert_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_w1\"] = experts_w1\n",
    "\n",
    "experts_b1 = randn(expert_num, 1, expert_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_b1\"] = experts_b1\n",
    "\n",
    "experts_w2 = randn(expert_num, expert_dim, emb_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_w2\"] = experts_w2\n",
    "\n",
    "experts_b2 = randn(expert_num, 1, emb_dim).astype(np.float32, order='C')\n",
    "exported[\"experts_b2\"] = experts_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd47b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scramble(a, axis=-1):\n",
    "    \"\"\"\n",
    "    Shuffle `a` in-place along the given axis.\n",
    "\n",
    "    Apply numpy.random.shuffle to the given axis of `a`.\n",
    "    Each one-dimensional slice is shuffled independently.\n",
    "    \"\"\"\n",
    "    b = a.swapaxes(axis, -1)\n",
    "    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n",
    "    # so `a` is shuffled in place, too.\n",
    "    shp = b.shape[:-1]\n",
    "    for ndx in np.ndindex(shp):\n",
    "        np.random.shuffle(b[ndx])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0525a698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 5)\n",
      "Total is 52.0, expected 52\n",
      "Expect around 10.4 per expert\n",
      "[10. 10.  9. 12. 11.]\n",
      "(5, 13)\n"
     ]
    }
   ],
   "source": [
    "# Generate random binary router\n",
    "\n",
    "router = np.zeros((token_num, expert_num)).astype(np.float32)\n",
    "print(router.shape)\n",
    "# Select K for TOP-K\n",
    "k = 4\n",
    "\n",
    "counter = 0\n",
    "expert = 0\n",
    "for t in range(token_num):\n",
    "    for counter in range(k):\n",
    "        router[t][expert + counter] = 1\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "#print(router)\n",
    "\n",
    "# router_shuf = np.transpose(router)\n",
    "scramble(router, axis=-1)\n",
    "# router = np.transpose(router_shuf)\n",
    "\n",
    "# Sanity check: sum per expert\n",
    "print(f'Total is {np.sum(router)}, expected {token_num * k}')\n",
    "print(f'Expect around {token_num * k / expert_num} per expert')\n",
    "print(np.sum(router, axis=0))\n",
    "\n",
    "# Order seems to be [token,expert]. Flip it back to [expert,token] to make the for-loop easier\n",
    "router = np.transpose(router)\n",
    "print(router.shape)\n",
    "\n",
    "# Router can be tiny, we just need booleans -> uint8. Also order='C' necessary otherwise it\n",
    "# will be saved flipped, since we transposed router and numpy implements this by just\n",
    "# changing the memory order marker.\n",
    "exported[\"router\"] = router.astype(np.uint8, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c6c741-407a-4d3b-a7e8-3d9555bebe99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70429174-2e92-44b1-8bf0-e4aed9a6a890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert 0:\n",
      "Expert 0 gets 10.0 tokens\n",
      "  (10, 11) * (11, 7) + (1, 7) = (10, 7)\n",
      "\n",
      "  (10, 7) * (7, 11) + (1, 11) = (10, 11)\n",
      "\n",
      "Expert 1:\n",
      "Expert 1 gets 10.0 tokens\n",
      "  (10, 11) * (11, 7) + (1, 7) = (10, 7)\n",
      "\n",
      "  (10, 7) * (7, 11) + (1, 11) = (10, 11)\n",
      "\n",
      "Expert 2:\n",
      "Expert 2 gets 9.0 tokens\n",
      "  (9, 11) * (11, 7) + (1, 7) = (9, 7)\n",
      "\n",
      "  (9, 7) * (7, 11) + (1, 11) = (9, 11)\n",
      "\n",
      "Expert 3:\n",
      "Expert 3 gets 12.0 tokens\n",
      "  (12, 11) * (11, 7) + (1, 7) = (12, 7)\n",
      "\n",
      "  (12, 7) * (7, 11) + (1, 11) = (12, 11)\n",
      "\n",
      "Expert 4:\n",
      "Expert 4 gets 11.0 tokens\n",
      "  (11, 11) * (11, 7) + (1, 7) = (11, 7)\n",
      "\n",
      "  (11, 7) * (7, 11) + (1, 11) = (11, 11)\n",
      "\n",
      "Total output: (13, 11)\n"
     ]
    }
   ],
   "source": [
    "# words(7) * emb_size(4)\n",
    "total_output = b * words # â€¦ so that if a word doesn't go through any expert it will still have some value\n",
    "\n",
    "# Repeat for every expert, looking at routed do determine which words go to said expert\n",
    "for n, expert_w1, expert_b1, expert_w2, expert_b2, mask in zip(count(), experts_w1, experts_b1, experts_w2, experts_b2, router):\n",
    "    print(f\"Expert {n}:\")\n",
    "    print(f\"Expert {n} gets {mask.sum()} tokens\")\n",
    "    assert mask.shape[0] == words.shape[0]\n",
    "    \n",
    "    # select all words where the mask for this expert is > 0\n",
    "    expert_input = words[mask.nonzero()]\n",
    "    \n",
    "    # classic matmul op for feed-forward I guess? + relu\n",
    "    expert_output1 = np.maximum(0.0, np.add(np.matmul(expert_input, expert_w1), expert_b1))\n",
    "    expert_output2 = np.maximum(0.0, np.add(np.matmul(expert_output1, expert_w2), expert_b2))\n",
    "    assert expert_output2.shape[0] == mask.sum()\n",
    "    \n",
    "    # Addition for all the selected experts.\n",
    "    # TODO: after loop: normalisation? We're now summing K experts + `b` of the original input.\n",
    "    total_output[mask.nonzero()] += expert_output2\n",
    "\n",
    "    print(f\"  {expert_input.shape} * {expert_w1.shape} + {expert_b1.shape} = {expert_output1.shape}\\n\")\n",
    "    print(f\"  {expert_output1.shape} * {expert_w2.shape} + {expert_b2.shape} = {expert_output2.shape}\\n\")\n",
    "    \n",
    "    exported[f\"expert_{n}_src\"] = expert_input.astype(np.float32, order='C')\n",
    "    exported[f\"expert_{n}_dst\"] = expert_output2.astype(np.float32, order='C')\n",
    "    \n",
    "print(f\"Total output: {total_output.shape}\")\n",
    "exported[\"dst\"] = total_output.astype(np.float32, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261b8f50-16b9-456d-be41-43a568d3b4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez(\"data.npz\", **exported)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b06da5d3-e159-4ea0-bdf7-5f6c81d38e5f",
   "metadata": {},
   "source": [
    "# Do grid search generation for various variable values. Save them to separate files.\n",
    "# Do not run automatically LOL\n",
    "\n",
    "expert_num_list = [8, 16, 32, 64, 128, 256] # number of experts\n",
    "expert_dim_list = [256, 512, 1024, 2048, 4096]\n",
    "emb_dim_list = [256, 512, 1024, 2048, 4096] # embedding size\n",
    "token_num_list = [128, 256, 512, 1024, 2048, 4096, 8192] # think token count, from unrolled batches possibly\n",
    "\n",
    "\n",
    "for expert_num in expert_num_list:\n",
    "    for expert_dim in expert_dim_list:\n",
    "        for emb_dim in emb_dim_list:\n",
    "            for token_num in token_num_list:\n",
    "                \n",
    "                exported = dict()\n",
    "                \n",
    "                # Generate input\n",
    "                words = randn(token_num, emb_dim).astype(np.float32)\n",
    "                exported[\"src\"] = words\n",
    "                \n",
    "                # Generate parameters\n",
    "                experts_w1 = randn(expert_num, emb_dim, expert_dim).astype(np.float32)\n",
    "                exported[\"experts_w1\"] = experts_w1\n",
    "\n",
    "                # expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "                experts_b1 = randn(expert_num, 1, expert_dim).astype(np.float32)\n",
    "                exported[\"experts_b1\"] = experts_b1\n",
    "\n",
    "                # expert (3) * emb_size (5) * emb_size (5)\n",
    "                experts_w2 = randn(expert_num, expert_dim, emb_dim).astype(np.float32)\n",
    "                exported[\"experts_w2\"] = experts_w2\n",
    "\n",
    "                # expert (3) * emb_prime_size (4) * emb_size (5)\n",
    "                experts_b2 = randn(expert_num, 1, emb_dim).astype(np.float32)\n",
    "                exported[\"experts_b2\"] = experts_b2\n",
    "\n",
    "                b = 0.1\n",
    "\n",
    "                # words(7) * emb_size(4)\n",
    "                total_output = b * words # â€¦ so that if a word doesn't go through any expert it will still have some value\n",
    "\n",
    "                # Repeat for every expert, looking at routed do determine which words go to said expert\n",
    "                for n, expert_w1, expert_b1, expert_w2, expert_b2, mask in zip(count(), experts_w1, experts_b1, experts_w2, experts_b2, router):\n",
    "                    #print(f\"Expert {n}:\")\n",
    "\n",
    "                    # select all words where the mask for this expert is > 0\n",
    "                    expert_input = words[mask.nonzero()]\n",
    "\n",
    "                    # classic matmul op for feed-forward I guess? + relu\n",
    "                    expert_output1 = np.maximum(0.0, np.add(np.matmul(expert_input, expert_w1), expert_b1))\n",
    "                    expert_output2 = np.maximum(0.0, np.add(np.matmul(expert_output1, expert_w2), expert_b2))\n",
    "\n",
    "                    # I did assignment here, but could also be addition\n",
    "                    total_output[mask.nonzero()] = expert_output2\n",
    "\n",
    "                    #print(f\"  {expert_input.shape} * {expert_w1.shape} + {expert_b1.shape} = {expert_output1.shape}\\n\")\n",
    "                    #print(f\"  {expert_output1.shape} * {expert_w2.shape} + {expert_b2.shape} = {expert_output2.shape}\\n\")\n",
    "\n",
    "                    exported[f\"expert_{n}_src\"] = expert_input\n",
    "                    exported[f\"expert_{n}_dst\"] = expert_output2\n",
    "\n",
    "                #print(f\"Total output: {total_output.shape}\")\n",
    "                exported[\"dst\"] = total_output\n",
    "                \n",
    "                file_name = \"exp-num_\" + str(expert_num) + \"_exp-dim_\" + str(expert_dim) + \"_emb-dim_\" + str(emb_dim) + \"_token-num_\" + str(token_num)\n",
    "                np.savez_compressed(file_name + \".npz\", **exported)\n",
    "                print(\"Finished \", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb31c3-0748-4002-815f-925ae1fb0267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e150e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
